I0311 13:26:51.636222 19870 caffe.cpp:184] Using GPUs 0
I0311 13:26:51.861325 19870 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet_basic"
solver_mode: GPU
device_id: 0
net: "examples/mnist/lenet_train_test.prototxt"
I0311 13:26:51.861480 19870 solver.cpp:91] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I0311 13:26:51.861960 19870 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0311 13:26:51.861987 19870 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0311 13:26:51.862110 19870 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0311 13:26:51.862205 19870 layer_factory.hpp:77] Creating layer mnist
I0311 13:26:51.862839 19870 net.cpp:106] Creating Layer mnist
I0311 13:26:51.862860 19870 net.cpp:411] mnist -> data
I0311 13:26:51.862896 19870 net.cpp:411] mnist -> label
I0311 13:26:51.863821 19874 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_train_lmdb
I0311 13:26:51.876250 19870 data_layer.cpp:41] output data size: 64,1,28,28
I0311 13:26:51.877674 19870 net.cpp:150] Setting up mnist
I0311 13:26:51.877701 19870 net.cpp:157] Top shape: 64 1 28 28 (50176)
I0311 13:26:51.877712 19870 net.cpp:157] Top shape: 64 (64)
I0311 13:26:51.877722 19870 net.cpp:165] Memory required for data: 200960
I0311 13:26:51.877737 19870 layer_factory.hpp:77] Creating layer conv1
I0311 13:26:51.877771 19870 net.cpp:106] Creating Layer conv1
I0311 13:26:51.877785 19870 net.cpp:454] conv1 <- data
I0311 13:26:51.877804 19870 net.cpp:411] conv1 -> conv1
I0311 13:26:52.046272 19870 net.cpp:150] Setting up conv1
I0311 13:26:52.046315 19870 net.cpp:157] Top shape: 64 20 24 24 (737280)
I0311 13:26:52.046325 19870 net.cpp:165] Memory required for data: 3150080
I0311 13:26:52.046351 19870 layer_factory.hpp:77] Creating layer pool1
I0311 13:26:52.046375 19870 net.cpp:106] Creating Layer pool1
I0311 13:26:52.046386 19870 net.cpp:454] pool1 <- conv1
I0311 13:26:52.046397 19870 net.cpp:411] pool1 -> pool1
I0311 13:26:52.047268 19870 net.cpp:150] Setting up pool1
I0311 13:26:52.047288 19870 net.cpp:157] Top shape: 64 20 12 12 (184320)
I0311 13:26:52.047294 19870 net.cpp:165] Memory required for data: 3887360
I0311 13:26:52.047300 19870 layer_factory.hpp:77] Creating layer conv2
I0311 13:26:52.047318 19870 net.cpp:106] Creating Layer conv2
I0311 13:26:52.047327 19870 net.cpp:454] conv2 <- pool1
I0311 13:26:52.047336 19870 net.cpp:411] conv2 -> conv2
I0311 13:26:52.050338 19870 net.cpp:150] Setting up conv2
I0311 13:26:52.050362 19870 net.cpp:157] Top shape: 64 50 8 8 (204800)
I0311 13:26:52.050370 19870 net.cpp:165] Memory required for data: 4706560
I0311 13:26:52.050385 19870 layer_factory.hpp:77] Creating layer pool2
I0311 13:26:52.050401 19870 net.cpp:106] Creating Layer pool2
I0311 13:26:52.050410 19870 net.cpp:454] pool2 <- conv2
I0311 13:26:52.050420 19870 net.cpp:411] pool2 -> pool2
I0311 13:26:52.051266 19870 net.cpp:150] Setting up pool2
I0311 13:26:52.051287 19870 net.cpp:157] Top shape: 64 50 4 4 (51200)
I0311 13:26:52.051295 19870 net.cpp:165] Memory required for data: 4911360
I0311 13:26:52.051301 19870 layer_factory.hpp:77] Creating layer ip1
I0311 13:26:52.051324 19870 net.cpp:106] Creating Layer ip1
I0311 13:26:52.051332 19870 net.cpp:454] ip1 <- pool2
I0311 13:26:52.051342 19870 net.cpp:411] ip1 -> ip1
I0311 13:26:52.054801 19870 net.cpp:150] Setting up ip1
I0311 13:26:52.054862 19870 net.cpp:157] Top shape: 64 500 (32000)
I0311 13:26:52.054893 19870 net.cpp:165] Memory required for data: 5039360
I0311 13:26:52.054932 19870 layer_factory.hpp:77] Creating layer relu1
I0311 13:26:52.054965 19870 net.cpp:106] Creating Layer relu1
I0311 13:26:52.054994 19870 net.cpp:454] relu1 <- ip1
I0311 13:26:52.055024 19870 net.cpp:397] relu1 -> ip1 (in-place)
I0311 13:26:52.056001 19870 net.cpp:150] Setting up relu1
I0311 13:26:52.056043 19870 net.cpp:157] Top shape: 64 500 (32000)
I0311 13:26:52.056071 19870 net.cpp:165] Memory required for data: 5167360
I0311 13:26:52.056097 19870 layer_factory.hpp:77] Creating layer ip2
I0311 13:26:52.056129 19870 net.cpp:106] Creating Layer ip2
I0311 13:26:52.056155 19870 net.cpp:454] ip2 <- ip1
I0311 13:26:52.056187 19870 net.cpp:411] ip2 -> ip2
I0311 13:26:52.056874 19870 net.cpp:150] Setting up ip2
I0311 13:26:52.056920 19870 net.cpp:157] Top shape: 64 10 (640)
I0311 13:26:52.056947 19870 net.cpp:165] Memory required for data: 5169920
I0311 13:26:52.056977 19870 layer_factory.hpp:77] Creating layer loss
I0311 13:26:52.057021 19870 net.cpp:106] Creating Layer loss
I0311 13:26:52.057049 19870 net.cpp:454] loss <- ip2
I0311 13:26:52.057076 19870 net.cpp:454] loss <- label
I0311 13:26:52.057104 19870 net.cpp:411] loss -> loss
I0311 13:26:52.057143 19870 layer_factory.hpp:77] Creating layer loss
I0311 13:26:52.058184 19870 net.cpp:150] Setting up loss
I0311 13:26:52.058224 19870 net.cpp:157] Top shape: (1)
I0311 13:26:52.058249 19870 net.cpp:160]     with loss weight 1
I0311 13:26:52.058284 19870 net.cpp:165] Memory required for data: 5169924
I0311 13:26:52.058307 19870 net.cpp:226] loss needs backward computation.
I0311 13:26:52.058333 19870 net.cpp:226] ip2 needs backward computation.
I0311 13:26:52.058357 19870 net.cpp:226] relu1 needs backward computation.
I0311 13:26:52.058380 19870 net.cpp:226] ip1 needs backward computation.
I0311 13:26:52.058404 19870 net.cpp:226] pool2 needs backward computation.
I0311 13:26:52.058429 19870 net.cpp:226] conv2 needs backward computation.
I0311 13:26:52.058454 19870 net.cpp:226] pool1 needs backward computation.
I0311 13:26:52.058477 19870 net.cpp:226] conv1 needs backward computation.
I0311 13:26:52.058501 19870 net.cpp:228] mnist does not need backward computation.
I0311 13:26:52.058522 19870 net.cpp:270] This network produces output loss
I0311 13:26:52.058552 19870 net.cpp:283] Network initialization done.
I0311 13:26:52.059062 19870 solver.cpp:181] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I0311 13:26:52.059123 19870 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0311 13:26:52.059289 19870 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0311 13:26:52.059900 19870 layer_factory.hpp:77] Creating layer mnist
I0311 13:26:52.060066 19870 net.cpp:106] Creating Layer mnist
I0311 13:26:52.060128 19870 net.cpp:411] mnist -> data
I0311 13:26:52.060168 19870 net.cpp:411] mnist -> label
I0311 13:26:52.061133 19876 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_test_lmdb
I0311 13:26:52.061290 19870 data_layer.cpp:41] output data size: 100,1,28,28
I0311 13:26:52.062839 19870 net.cpp:150] Setting up mnist
I0311 13:26:52.062904 19870 net.cpp:157] Top shape: 100 1 28 28 (78400)
I0311 13:26:52.062932 19870 net.cpp:157] Top shape: 100 (100)
I0311 13:26:52.062968 19870 net.cpp:165] Memory required for data: 314000
I0311 13:26:52.062994 19870 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0311 13:26:52.063025 19870 net.cpp:106] Creating Layer label_mnist_1_split
I0311 13:26:52.063052 19870 net.cpp:454] label_mnist_1_split <- label
I0311 13:26:52.063081 19870 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_0
I0311 13:26:52.063117 19870 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_1
I0311 13:26:52.063201 19870 net.cpp:150] Setting up label_mnist_1_split
I0311 13:26:52.063235 19870 net.cpp:157] Top shape: 100 (100)
I0311 13:26:52.063261 19870 net.cpp:157] Top shape: 100 (100)
I0311 13:26:52.063282 19870 net.cpp:165] Memory required for data: 314800
I0311 13:26:52.063304 19870 layer_factory.hpp:77] Creating layer conv1
I0311 13:26:52.063339 19870 net.cpp:106] Creating Layer conv1
I0311 13:26:52.063365 19870 net.cpp:454] conv1 <- data
I0311 13:26:52.063396 19870 net.cpp:411] conv1 -> conv1
I0311 13:26:52.066949 19870 net.cpp:150] Setting up conv1
I0311 13:26:52.067008 19870 net.cpp:157] Top shape: 100 20 24 24 (1152000)
I0311 13:26:52.067036 19870 net.cpp:165] Memory required for data: 4922800
I0311 13:26:52.067081 19870 layer_factory.hpp:77] Creating layer pool1
I0311 13:26:52.067116 19870 net.cpp:106] Creating Layer pool1
I0311 13:26:52.067159 19870 net.cpp:454] pool1 <- conv1
I0311 13:26:52.067203 19870 net.cpp:411] pool1 -> pool1
I0311 13:26:52.068167 19870 net.cpp:150] Setting up pool1
I0311 13:26:52.068207 19870 net.cpp:157] Top shape: 100 20 12 12 (288000)
I0311 13:26:52.068244 19870 net.cpp:165] Memory required for data: 6074800
I0311 13:26:52.068272 19870 layer_factory.hpp:77] Creating layer conv2
I0311 13:26:52.068310 19870 net.cpp:106] Creating Layer conv2
I0311 13:26:52.068336 19870 net.cpp:454] conv2 <- pool1
I0311 13:26:52.068368 19870 net.cpp:411] conv2 -> conv2
I0311 13:26:52.071698 19870 net.cpp:150] Setting up conv2
I0311 13:26:52.071758 19870 net.cpp:157] Top shape: 100 50 8 8 (320000)
I0311 13:26:52.071796 19870 net.cpp:165] Memory required for data: 7354800
I0311 13:26:52.071835 19870 layer_factory.hpp:77] Creating layer pool2
I0311 13:26:52.071866 19870 net.cpp:106] Creating Layer pool2
I0311 13:26:52.071892 19870 net.cpp:454] pool2 <- conv2
I0311 13:26:52.071920 19870 net.cpp:411] pool2 -> pool2
I0311 13:26:52.073006 19870 net.cpp:150] Setting up pool2
I0311 13:26:52.073047 19870 net.cpp:157] Top shape: 100 50 4 4 (80000)
I0311 13:26:52.073070 19870 net.cpp:165] Memory required for data: 7674800
I0311 13:26:52.073088 19870 layer_factory.hpp:77] Creating layer ip1
I0311 13:26:52.073117 19870 net.cpp:106] Creating Layer ip1
I0311 13:26:52.073153 19870 net.cpp:454] ip1 <- pool2
I0311 13:26:52.073185 19870 net.cpp:411] ip1 -> ip1
I0311 13:26:52.076674 19870 net.cpp:150] Setting up ip1
I0311 13:26:52.076756 19870 net.cpp:157] Top shape: 100 500 (50000)
I0311 13:26:52.076782 19870 net.cpp:165] Memory required for data: 7874800
I0311 13:26:52.076822 19870 layer_factory.hpp:77] Creating layer relu1
I0311 13:26:52.076858 19870 net.cpp:106] Creating Layer relu1
I0311 13:26:52.076886 19870 net.cpp:454] relu1 <- ip1
I0311 13:26:52.076925 19870 net.cpp:397] relu1 -> ip1 (in-place)
I0311 13:26:52.077925 19870 net.cpp:150] Setting up relu1
I0311 13:26:52.077966 19870 net.cpp:157] Top shape: 100 500 (50000)
I0311 13:26:52.077994 19870 net.cpp:165] Memory required for data: 8074800
I0311 13:26:52.078021 19870 layer_factory.hpp:77] Creating layer ip2
I0311 13:26:52.078057 19870 net.cpp:106] Creating Layer ip2
I0311 13:26:52.078086 19870 net.cpp:454] ip2 <- ip1
I0311 13:26:52.078119 19870 net.cpp:411] ip2 -> ip2
I0311 13:26:52.078349 19870 net.cpp:150] Setting up ip2
I0311 13:26:52.078384 19870 net.cpp:157] Top shape: 100 10 (1000)
I0311 13:26:52.078410 19870 net.cpp:165] Memory required for data: 8078800
I0311 13:26:52.078441 19870 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0311 13:26:52.078469 19870 net.cpp:106] Creating Layer ip2_ip2_0_split
I0311 13:26:52.078496 19870 net.cpp:454] ip2_ip2_0_split <- ip2
I0311 13:26:52.078527 19870 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0311 13:26:52.078558 19870 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0311 13:26:52.078636 19870 net.cpp:150] Setting up ip2_ip2_0_split
I0311 13:26:52.078670 19870 net.cpp:157] Top shape: 100 10 (1000)
I0311 13:26:52.078698 19870 net.cpp:157] Top shape: 100 10 (1000)
I0311 13:26:52.078724 19870 net.cpp:165] Memory required for data: 8086800
I0311 13:26:52.078748 19870 layer_factory.hpp:77] Creating layer accuracy
I0311 13:26:52.078780 19870 net.cpp:106] Creating Layer accuracy
I0311 13:26:52.078816 19870 net.cpp:454] accuracy <- ip2_ip2_0_split_0
I0311 13:26:52.078845 19870 net.cpp:454] accuracy <- label_mnist_1_split_0
I0311 13:26:52.078873 19870 net.cpp:411] accuracy -> accuracy
I0311 13:26:52.078912 19870 net.cpp:150] Setting up accuracy
I0311 13:26:52.078941 19870 net.cpp:157] Top shape: (1)
I0311 13:26:52.078968 19870 net.cpp:165] Memory required for data: 8086804
I0311 13:26:52.078992 19870 layer_factory.hpp:77] Creating layer loss
I0311 13:26:52.079021 19870 net.cpp:106] Creating Layer loss
I0311 13:26:52.079046 19870 net.cpp:454] loss <- ip2_ip2_0_split_1
I0311 13:26:52.079073 19870 net.cpp:454] loss <- label_mnist_1_split_1
I0311 13:26:52.079099 19870 net.cpp:411] loss -> loss
I0311 13:26:52.079133 19870 layer_factory.hpp:77] Creating layer loss
I0311 13:26:52.080209 19870 net.cpp:150] Setting up loss
I0311 13:26:52.080246 19870 net.cpp:157] Top shape: (1)
I0311 13:26:52.080273 19870 net.cpp:160]     with loss weight 1
I0311 13:26:52.080304 19870 net.cpp:165] Memory required for data: 8086808
I0311 13:26:52.080330 19870 net.cpp:226] loss needs backward computation.
I0311 13:26:52.080358 19870 net.cpp:228] accuracy does not need backward computation.
I0311 13:26:52.080382 19870 net.cpp:226] ip2_ip2_0_split needs backward computation.
I0311 13:26:52.080407 19870 net.cpp:226] ip2 needs backward computation.
I0311 13:26:52.080433 19870 net.cpp:226] relu1 needs backward computation.
I0311 13:26:52.080457 19870 net.cpp:226] ip1 needs backward computation.
I0311 13:26:52.080482 19870 net.cpp:226] pool2 needs backward computation.
I0311 13:26:52.080505 19870 net.cpp:226] conv2 needs backward computation.
I0311 13:26:52.080530 19870 net.cpp:226] pool1 needs backward computation.
I0311 13:26:52.080555 19870 net.cpp:226] conv1 needs backward computation.
I0311 13:26:52.080580 19870 net.cpp:228] label_mnist_1_split does not need backward computation.
I0311 13:26:52.080606 19870 net.cpp:228] mnist does not need backward computation.
I0311 13:26:52.080631 19870 net.cpp:270] This network produces output accuracy
I0311 13:26:52.080653 19870 net.cpp:270] This network produces output loss
I0311 13:26:52.080695 19870 net.cpp:283] Network initialization done.
I0311 13:26:52.080808 19870 solver.cpp:60] Solver scaffolding done.
I0311 13:26:52.081290 19870 caffe.cpp:212] Starting Optimization
I0311 13:26:52.081329 19870 solver.cpp:288] Solving LeNet
I0311 13:26:52.081354 19870 solver.cpp:289] Learning Rate Policy: inv
I0311 13:26:52.081917 19870 solver.cpp:341] Iteration 0, Testing net (#0)
I0311 13:26:52.286248 19870 solver.cpp:409]     Test net output #0: accuracy = 0.0898
I0311 13:26:52.286336 19870 solver.cpp:409]     Test net output #1: loss = 2.37649 (* 1 = 2.37649 loss)
I0311 13:26:52.289819 19870 solver.cpp:237] Iteration 0, loss = 2.37825
I0311 13:26:52.289885 19870 solver.cpp:253]     Train net output #0: loss = 2.37825 (* 1 = 2.37825 loss)
I0311 13:26:52.289929 19870 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0311 13:26:52.553686 19870 blocking_queue.cpp:50] Data layer prefetch queue empty
I0311 13:26:52.622337 19870 solver.cpp:237] Iteration 100, loss = 0.184608
I0311 13:26:52.622426 19870 solver.cpp:253]     Train net output #0: loss = 0.184608 (* 1 = 0.184608 loss)
I0311 13:26:52.622460 19870 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0311 13:26:52.953330 19870 solver.cpp:237] Iteration 200, loss = 0.160621
I0311 13:26:52.953421 19870 solver.cpp:253]     Train net output #0: loss = 0.160621 (* 1 = 0.160621 loss)
I0311 13:26:52.953455 19870 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0311 13:26:53.283179 19870 solver.cpp:237] Iteration 300, loss = 0.13919
I0311 13:26:53.283211 19870 solver.cpp:253]     Train net output #0: loss = 0.13919 (* 1 = 0.13919 loss)
I0311 13:26:53.283221 19870 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0311 13:26:53.606302 19870 solver.cpp:237] Iteration 400, loss = 0.0955126
I0311 13:26:53.606336 19870 solver.cpp:253]     Train net output #0: loss = 0.0955126 (* 1 = 0.0955126 loss)
I0311 13:26:53.606345 19870 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0311 13:26:53.959529 19870 solver.cpp:341] Iteration 500, Testing net (#0)
I0311 13:26:54.152663 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9749
I0311 13:26:54.152698 19870 solver.cpp:409]     Test net output #1: loss = 0.0800055 (* 1 = 0.0800055 loss)
I0311 13:26:54.154273 19870 solver.cpp:237] Iteration 500, loss = 0.123658
I0311 13:26:54.154294 19870 solver.cpp:253]     Train net output #0: loss = 0.123658 (* 1 = 0.123658 loss)
I0311 13:26:54.154304 19870 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0311 13:26:54.488065 19870 solver.cpp:237] Iteration 600, loss = 0.0879576
I0311 13:26:54.488101 19870 solver.cpp:253]     Train net output #0: loss = 0.0879577 (* 1 = 0.0879577 loss)
I0311 13:26:54.488111 19870 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0311 13:26:54.825551 19870 solver.cpp:237] Iteration 700, loss = 0.0967433
I0311 13:26:54.825587 19870 solver.cpp:253]     Train net output #0: loss = 0.0967434 (* 1 = 0.0967434 loss)
I0311 13:26:54.825598 19870 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0311 13:26:55.163897 19870 solver.cpp:237] Iteration 800, loss = 0.209912
I0311 13:26:55.163935 19870 solver.cpp:253]     Train net output #0: loss = 0.209912 (* 1 = 0.209912 loss)
I0311 13:26:55.163946 19870 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0311 13:26:55.502219 19870 solver.cpp:237] Iteration 900, loss = 0.138005
I0311 13:26:55.502254 19870 solver.cpp:253]     Train net output #0: loss = 0.138006 (* 1 = 0.138006 loss)
I0311 13:26:55.502262 19870 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0311 13:26:55.837044 19870 solver.cpp:341] Iteration 1000, Testing net (#0)
I0311 13:26:56.047862 19870 solver.cpp:409]     Test net output #0: accuracy = 0.983
I0311 13:26:56.047902 19870 solver.cpp:409]     Test net output #1: loss = 0.0558996 (* 1 = 0.0558996 loss)
I0311 13:26:56.050058 19870 solver.cpp:237] Iteration 1000, loss = 0.0600763
I0311 13:26:56.050078 19870 solver.cpp:253]     Train net output #0: loss = 0.0600765 (* 1 = 0.0600765 loss)
I0311 13:26:56.050089 19870 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0311 13:26:56.397430 19870 solver.cpp:237] Iteration 1100, loss = 0.00476423
I0311 13:26:56.397461 19870 solver.cpp:253]     Train net output #0: loss = 0.00476437 (* 1 = 0.00476437 loss)
I0311 13:26:56.397471 19870 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0311 13:26:56.747817 19870 solver.cpp:237] Iteration 1200, loss = 0.0227241
I0311 13:26:56.747851 19870 solver.cpp:253]     Train net output #0: loss = 0.0227242 (* 1 = 0.0227242 loss)
I0311 13:26:56.747860 19870 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0311 13:26:57.097656 19870 solver.cpp:237] Iteration 1300, loss = 0.0186188
I0311 13:26:57.097688 19870 solver.cpp:253]     Train net output #0: loss = 0.0186189 (* 1 = 0.0186189 loss)
I0311 13:26:57.097698 19870 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0311 13:26:57.440485 19870 solver.cpp:237] Iteration 1400, loss = 0.00717637
I0311 13:26:57.440518 19870 solver.cpp:253]     Train net output #0: loss = 0.00717653 (* 1 = 0.00717653 loss)
I0311 13:26:57.440528 19870 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0311 13:26:57.784296 19870 solver.cpp:341] Iteration 1500, Testing net (#0)
I0311 13:26:57.994524 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9854
I0311 13:26:57.994557 19870 solver.cpp:409]     Test net output #1: loss = 0.0490544 (* 1 = 0.0490544 loss)
I0311 13:26:57.996395 19870 solver.cpp:237] Iteration 1500, loss = 0.0470769
I0311 13:26:57.996415 19870 solver.cpp:253]     Train net output #0: loss = 0.047077 (* 1 = 0.047077 loss)
I0311 13:26:57.996428 19870 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0311 13:26:58.351176 19870 solver.cpp:237] Iteration 1600, loss = 0.0832565
I0311 13:26:58.351208 19870 solver.cpp:253]     Train net output #0: loss = 0.0832566 (* 1 = 0.0832566 loss)
I0311 13:26:58.351217 19870 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0311 13:26:58.709302 19870 solver.cpp:237] Iteration 1700, loss = 0.0343602
I0311 13:26:58.709333 19870 solver.cpp:253]     Train net output #0: loss = 0.0343603 (* 1 = 0.0343603 loss)
I0311 13:26:58.709343 19870 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0311 13:26:59.068065 19870 solver.cpp:237] Iteration 1800, loss = 0.012501
I0311 13:26:59.068099 19870 solver.cpp:253]     Train net output #0: loss = 0.0125012 (* 1 = 0.0125012 loss)
I0311 13:26:59.068109 19870 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0311 13:26:59.425904 19870 solver.cpp:237] Iteration 1900, loss = 0.12012
I0311 13:26:59.425938 19870 solver.cpp:253]     Train net output #0: loss = 0.12012 (* 1 = 0.12012 loss)
I0311 13:26:59.425948 19870 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0311 13:26:59.781276 19870 solver.cpp:341] Iteration 2000, Testing net (#0)
I0311 13:27:00.029072 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9867
I0311 13:27:00.029165 19870 solver.cpp:409]     Test net output #1: loss = 0.0407674 (* 1 = 0.0407674 loss)
I0311 13:27:00.031647 19870 solver.cpp:237] Iteration 2000, loss = 0.0127383
I0311 13:27:00.031703 19870 solver.cpp:253]     Train net output #0: loss = 0.0127385 (* 1 = 0.0127385 loss)
I0311 13:27:00.031738 19870 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0311 13:27:00.411903 19870 solver.cpp:237] Iteration 2100, loss = 0.012123
I0311 13:27:00.411938 19870 solver.cpp:253]     Train net output #0: loss = 0.0121232 (* 1 = 0.0121232 loss)
I0311 13:27:00.411948 19870 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0311 13:27:00.769939 19870 solver.cpp:237] Iteration 2200, loss = 0.0081905
I0311 13:27:00.769975 19870 solver.cpp:253]     Train net output #0: loss = 0.00819065 (* 1 = 0.00819065 loss)
I0311 13:27:00.769985 19870 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0311 13:27:01.128036 19870 solver.cpp:237] Iteration 2300, loss = 0.0853322
I0311 13:27:01.128068 19870 solver.cpp:253]     Train net output #0: loss = 0.0853324 (* 1 = 0.0853324 loss)
I0311 13:27:01.128078 19870 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0311 13:27:01.487608 19870 solver.cpp:237] Iteration 2400, loss = 0.0122602
I0311 13:27:01.487643 19870 solver.cpp:253]     Train net output #0: loss = 0.0122604 (* 1 = 0.0122604 loss)
I0311 13:27:01.487653 19870 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0311 13:27:01.848469 19870 solver.cpp:341] Iteration 2500, Testing net (#0)
I0311 13:27:02.060266 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9859
I0311 13:27:02.060298 19870 solver.cpp:409]     Test net output #1: loss = 0.0445426 (* 1 = 0.0445426 loss)
I0311 13:27:02.062454 19870 solver.cpp:237] Iteration 2500, loss = 0.0336964
I0311 13:27:02.062474 19870 solver.cpp:253]     Train net output #0: loss = 0.0336966 (* 1 = 0.0336966 loss)
I0311 13:27:02.062486 19870 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0311 13:27:02.425796 19870 solver.cpp:237] Iteration 2600, loss = 0.0558211
I0311 13:27:02.425830 19870 solver.cpp:253]     Train net output #0: loss = 0.0558213 (* 1 = 0.0558213 loss)
I0311 13:27:02.425840 19870 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0311 13:27:02.769513 19870 solver.cpp:237] Iteration 2700, loss = 0.0489509
I0311 13:27:02.769546 19870 solver.cpp:253]     Train net output #0: loss = 0.0489511 (* 1 = 0.0489511 loss)
I0311 13:27:02.769556 19870 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0311 13:27:03.109882 19870 solver.cpp:237] Iteration 2800, loss = 0.00309282
I0311 13:27:03.109915 19870 solver.cpp:253]     Train net output #0: loss = 0.003093 (* 1 = 0.003093 loss)
I0311 13:27:03.109925 19870 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0311 13:27:03.455418 19870 solver.cpp:237] Iteration 2900, loss = 0.0154438
I0311 13:27:03.455452 19870 solver.cpp:253]     Train net output #0: loss = 0.015444 (* 1 = 0.015444 loss)
I0311 13:27:03.455462 19870 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0311 13:27:03.799564 19870 solver.cpp:341] Iteration 3000, Testing net (#0)
I0311 13:27:04.009063 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9874
I0311 13:27:04.009096 19870 solver.cpp:409]     Test net output #1: loss = 0.0388067 (* 1 = 0.0388067 loss)
I0311 13:27:04.011025 19870 solver.cpp:237] Iteration 3000, loss = 0.0062896
I0311 13:27:04.011076 19870 solver.cpp:253]     Train net output #0: loss = 0.00628976 (* 1 = 0.00628976 loss)
I0311 13:27:04.011092 19870 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0311 13:27:04.364588 19870 solver.cpp:237] Iteration 3100, loss = 0.023302
I0311 13:27:04.364620 19870 solver.cpp:253]     Train net output #0: loss = 0.0233022 (* 1 = 0.0233022 loss)
I0311 13:27:04.364631 19870 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0311 13:27:04.719403 19870 solver.cpp:237] Iteration 3200, loss = 0.0077268
I0311 13:27:04.719435 19870 solver.cpp:253]     Train net output #0: loss = 0.00772696 (* 1 = 0.00772696 loss)
I0311 13:27:04.719477 19870 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0311 13:27:05.075518 19870 solver.cpp:237] Iteration 3300, loss = 0.0438424
I0311 13:27:05.075553 19870 solver.cpp:253]     Train net output #0: loss = 0.0438426 (* 1 = 0.0438426 loss)
I0311 13:27:05.075563 19870 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0311 13:27:05.427294 19870 solver.cpp:237] Iteration 3400, loss = 0.0138894
I0311 13:27:05.427326 19870 solver.cpp:253]     Train net output #0: loss = 0.0138896 (* 1 = 0.0138896 loss)
I0311 13:27:05.427335 19870 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0311 13:27:05.777961 19870 solver.cpp:341] Iteration 3500, Testing net (#0)
I0311 13:27:05.991479 19870 solver.cpp:409]     Test net output #0: accuracy = 0.988
I0311 13:27:05.991513 19870 solver.cpp:409]     Test net output #1: loss = 0.0384159 (* 1 = 0.0384159 loss)
I0311 13:27:05.992862 19870 solver.cpp:237] Iteration 3500, loss = 0.00667933
I0311 13:27:05.992882 19870 solver.cpp:253]     Train net output #0: loss = 0.00667949 (* 1 = 0.00667949 loss)
I0311 13:27:05.992899 19870 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0311 13:27:06.327806 19870 solver.cpp:237] Iteration 3600, loss = 0.0227368
I0311 13:27:06.327841 19870 solver.cpp:253]     Train net output #0: loss = 0.022737 (* 1 = 0.022737 loss)
I0311 13:27:06.327850 19870 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0311 13:27:06.674314 19870 solver.cpp:237] Iteration 3700, loss = 0.0157516
I0311 13:27:06.674346 19870 solver.cpp:253]     Train net output #0: loss = 0.0157517 (* 1 = 0.0157517 loss)
I0311 13:27:06.674356 19870 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0311 13:27:07.025527 19870 solver.cpp:237] Iteration 3800, loss = 0.0108314
I0311 13:27:07.025560 19870 solver.cpp:253]     Train net output #0: loss = 0.0108316 (* 1 = 0.0108316 loss)
I0311 13:27:07.025570 19870 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0311 13:27:07.388396 19870 solver.cpp:237] Iteration 3900, loss = 0.0360336
I0311 13:27:07.388432 19870 solver.cpp:253]     Train net output #0: loss = 0.0360338 (* 1 = 0.0360338 loss)
I0311 13:27:07.388440 19870 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0311 13:27:07.739712 19870 solver.cpp:341] Iteration 4000, Testing net (#0)
I0311 13:27:07.950883 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9901
I0311 13:27:07.950917 19870 solver.cpp:409]     Test net output #1: loss = 0.0300884 (* 1 = 0.0300884 loss)
I0311 13:27:07.952489 19870 solver.cpp:237] Iteration 4000, loss = 0.0199835
I0311 13:27:07.952509 19870 solver.cpp:253]     Train net output #0: loss = 0.0199837 (* 1 = 0.0199837 loss)
I0311 13:27:07.952520 19870 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0311 13:27:08.302848 19870 solver.cpp:237] Iteration 4100, loss = 0.0197983
I0311 13:27:08.302882 19870 solver.cpp:253]     Train net output #0: loss = 0.0197985 (* 1 = 0.0197985 loss)
I0311 13:27:08.302892 19870 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0311 13:27:08.673780 19870 solver.cpp:237] Iteration 4200, loss = 0.0139413
I0311 13:27:08.673812 19870 solver.cpp:253]     Train net output #0: loss = 0.0139415 (* 1 = 0.0139415 loss)
I0311 13:27:08.673822 19870 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0311 13:27:09.033407 19870 solver.cpp:237] Iteration 4300, loss = 0.0377949
I0311 13:27:09.033442 19870 solver.cpp:253]     Train net output #0: loss = 0.0377951 (* 1 = 0.0377951 loss)
I0311 13:27:09.033452 19870 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0311 13:27:09.393008 19870 solver.cpp:237] Iteration 4400, loss = 0.0157337
I0311 13:27:09.393043 19870 solver.cpp:253]     Train net output #0: loss = 0.0157339 (* 1 = 0.0157339 loss)
I0311 13:27:09.393054 19870 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0311 13:27:09.767293 19870 solver.cpp:341] Iteration 4500, Testing net (#0)
I0311 13:27:09.977948 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9886
I0311 13:27:09.977980 19870 solver.cpp:409]     Test net output #1: loss = 0.0343227 (* 1 = 0.0343227 loss)
I0311 13:27:09.980176 19870 solver.cpp:237] Iteration 4500, loss = 0.00681337
I0311 13:27:09.980197 19870 solver.cpp:253]     Train net output #0: loss = 0.00681355 (* 1 = 0.00681355 loss)
I0311 13:27:09.980209 19870 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0311 13:27:10.348325 19870 solver.cpp:237] Iteration 4600, loss = 0.0154336
I0311 13:27:10.348361 19870 solver.cpp:253]     Train net output #0: loss = 0.0154338 (* 1 = 0.0154338 loss)
I0311 13:27:10.348371 19870 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0311 13:27:10.695287 19870 solver.cpp:237] Iteration 4700, loss = 0.00320181
I0311 13:27:10.695322 19870 solver.cpp:253]     Train net output #0: loss = 0.00320198 (* 1 = 0.00320198 loss)
I0311 13:27:10.695330 19870 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0311 13:27:11.037129 19870 solver.cpp:237] Iteration 4800, loss = 0.0180009
I0311 13:27:11.037163 19870 solver.cpp:253]     Train net output #0: loss = 0.0180011 (* 1 = 0.0180011 loss)
I0311 13:27:11.037173 19870 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0311 13:27:11.380014 19870 solver.cpp:237] Iteration 4900, loss = 0.00492061
I0311 13:27:11.380048 19870 solver.cpp:253]     Train net output #0: loss = 0.00492078 (* 1 = 0.00492078 loss)
I0311 13:27:11.380056 19870 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0311 13:27:11.714584 19870 solver.cpp:459] Snapshotting to binary proto file examples/mnist/lenet_basic_iter_5000.caffemodel
I0311 13:27:12.104001 19870 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/lenet_basic_iter_5000.solverstate
I0311 13:27:12.106204 19870 solver.cpp:341] Iteration 5000, Testing net (#0)
I0311 13:27:12.309152 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9903
I0311 13:27:12.309185 19870 solver.cpp:409]     Test net output #1: loss = 0.030031 (* 1 = 0.030031 loss)
I0311 13:27:12.310575 19870 solver.cpp:237] Iteration 5000, loss = 0.0219529
I0311 13:27:12.310595 19870 solver.cpp:253]     Train net output #0: loss = 0.0219531 (* 1 = 0.0219531 loss)
I0311 13:27:12.310607 19870 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0311 13:27:12.654677 19870 solver.cpp:237] Iteration 5100, loss = 0.0210716
I0311 13:27:12.654708 19870 solver.cpp:253]     Train net output #0: loss = 0.0210718 (* 1 = 0.0210718 loss)
I0311 13:27:12.654717 19870 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0311 13:27:12.996543 19870 solver.cpp:237] Iteration 5200, loss = 0.00794852
I0311 13:27:12.996578 19870 solver.cpp:253]     Train net output #0: loss = 0.00794868 (* 1 = 0.00794868 loss)
I0311 13:27:12.996588 19870 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0311 13:27:13.340440 19870 solver.cpp:237] Iteration 5300, loss = 0.00230866
I0311 13:27:13.340474 19870 solver.cpp:253]     Train net output #0: loss = 0.00230882 (* 1 = 0.00230882 loss)
I0311 13:27:13.340484 19870 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0311 13:27:13.686677 19870 solver.cpp:237] Iteration 5400, loss = 0.00691577
I0311 13:27:13.686710 19870 solver.cpp:253]     Train net output #0: loss = 0.00691594 (* 1 = 0.00691594 loss)
I0311 13:27:13.686720 19870 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0311 13:27:14.028079 19870 solver.cpp:341] Iteration 5500, Testing net (#0)
I0311 13:27:14.243549 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9886
I0311 13:27:14.243582 19870 solver.cpp:409]     Test net output #1: loss = 0.0325252 (* 1 = 0.0325252 loss)
I0311 13:27:14.245743 19870 solver.cpp:237] Iteration 5500, loss = 0.00786372
I0311 13:27:14.245765 19870 solver.cpp:253]     Train net output #0: loss = 0.00786389 (* 1 = 0.00786389 loss)
I0311 13:27:14.245776 19870 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0311 13:27:14.597715 19870 solver.cpp:237] Iteration 5600, loss = 0.000864891
I0311 13:27:14.597750 19870 solver.cpp:253]     Train net output #0: loss = 0.000865058 (* 1 = 0.000865058 loss)
I0311 13:27:14.597759 19870 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0311 13:27:14.971163 19870 solver.cpp:237] Iteration 5700, loss = 0.00573221
I0311 13:27:14.971278 19870 solver.cpp:253]     Train net output #0: loss = 0.00573237 (* 1 = 0.00573237 loss)
I0311 13:27:14.971307 19870 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0311 13:27:15.330960 19870 solver.cpp:237] Iteration 5800, loss = 0.0215022
I0311 13:27:15.330993 19870 solver.cpp:253]     Train net output #0: loss = 0.0215024 (* 1 = 0.0215024 loss)
I0311 13:27:15.331003 19870 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0311 13:27:15.679520 19870 solver.cpp:237] Iteration 5900, loss = 0.00353518
I0311 13:27:15.679554 19870 solver.cpp:253]     Train net output #0: loss = 0.00353535 (* 1 = 0.00353535 loss)
I0311 13:27:15.679563 19870 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0311 13:27:16.018450 19870 solver.cpp:341] Iteration 6000, Testing net (#0)
I0311 13:27:16.232169 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9913
I0311 13:27:16.232198 19870 solver.cpp:409]     Test net output #1: loss = 0.0273635 (* 1 = 0.0273635 loss)
I0311 13:27:16.234313 19870 solver.cpp:237] Iteration 6000, loss = 0.00541257
I0311 13:27:16.234333 19870 solver.cpp:253]     Train net output #0: loss = 0.00541274 (* 1 = 0.00541274 loss)
I0311 13:27:16.234344 19870 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0311 13:27:16.584377 19870 solver.cpp:237] Iteration 6100, loss = 0.00320014
I0311 13:27:16.584406 19870 solver.cpp:253]     Train net output #0: loss = 0.0032003 (* 1 = 0.0032003 loss)
I0311 13:27:16.584415 19870 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0311 13:27:16.940184 19870 solver.cpp:237] Iteration 6200, loss = 0.0089279
I0311 13:27:16.940217 19870 solver.cpp:253]     Train net output #0: loss = 0.00892806 (* 1 = 0.00892806 loss)
I0311 13:27:16.940227 19870 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0311 13:27:17.293259 19870 solver.cpp:237] Iteration 6300, loss = 0.00562961
I0311 13:27:17.293290 19870 solver.cpp:253]     Train net output #0: loss = 0.00562978 (* 1 = 0.00562978 loss)
I0311 13:27:17.293299 19870 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0311 13:27:17.648447 19870 solver.cpp:237] Iteration 6400, loss = 0.00781638
I0311 13:27:17.648481 19870 solver.cpp:253]     Train net output #0: loss = 0.00781654 (* 1 = 0.00781654 loss)
I0311 13:27:17.648491 19870 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0311 13:27:18.002789 19870 solver.cpp:341] Iteration 6500, Testing net (#0)
I0311 13:27:18.218381 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9907
I0311 13:27:18.218412 19870 solver.cpp:409]     Test net output #1: loss = 0.029581 (* 1 = 0.029581 loss)
I0311 13:27:18.220105 19870 solver.cpp:237] Iteration 6500, loss = 0.0105184
I0311 13:27:18.220126 19870 solver.cpp:253]     Train net output #0: loss = 0.0105186 (* 1 = 0.0105186 loss)
I0311 13:27:18.220139 19870 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0311 13:27:18.569239 19870 solver.cpp:237] Iteration 6600, loss = 0.0269767
I0311 13:27:18.569272 19870 solver.cpp:253]     Train net output #0: loss = 0.0269769 (* 1 = 0.0269769 loss)
I0311 13:27:18.569283 19870 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0311 13:27:18.915701 19870 solver.cpp:237] Iteration 6700, loss = 0.00527912
I0311 13:27:18.915735 19870 solver.cpp:253]     Train net output #0: loss = 0.00527929 (* 1 = 0.00527929 loss)
I0311 13:27:18.915745 19870 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0311 13:27:19.263519 19870 solver.cpp:237] Iteration 6800, loss = 0.00121677
I0311 13:27:19.263555 19870 solver.cpp:253]     Train net output #0: loss = 0.00121694 (* 1 = 0.00121694 loss)
I0311 13:27:19.263563 19870 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0311 13:27:19.616019 19870 solver.cpp:237] Iteration 6900, loss = 0.00610543
I0311 13:27:19.616051 19870 solver.cpp:253]     Train net output #0: loss = 0.0061056 (* 1 = 0.0061056 loss)
I0311 13:27:19.616062 19870 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0311 13:27:19.964818 19870 solver.cpp:341] Iteration 7000, Testing net (#0)
I0311 13:27:20.178380 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9907
I0311 13:27:20.178442 19870 solver.cpp:409]     Test net output #1: loss = 0.0295458 (* 1 = 0.0295458 loss)
I0311 13:27:20.180359 19870 solver.cpp:237] Iteration 7000, loss = 0.0097354
I0311 13:27:20.180380 19870 solver.cpp:253]     Train net output #0: loss = 0.00973555 (* 1 = 0.00973555 loss)
I0311 13:27:20.180392 19870 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0311 13:27:20.528151 19870 solver.cpp:237] Iteration 7100, loss = 0.0102611
I0311 13:27:20.528184 19870 solver.cpp:253]     Train net output #0: loss = 0.0102613 (* 1 = 0.0102613 loss)
I0311 13:27:20.528193 19870 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0311 13:27:20.877789 19870 solver.cpp:237] Iteration 7200, loss = 0.0109473
I0311 13:27:20.877820 19870 solver.cpp:253]     Train net output #0: loss = 0.0109475 (* 1 = 0.0109475 loss)
I0311 13:27:20.877830 19870 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0311 13:27:21.224409 19870 solver.cpp:237] Iteration 7300, loss = 0.0260629
I0311 13:27:21.224447 19870 solver.cpp:253]     Train net output #0: loss = 0.0260631 (* 1 = 0.0260631 loss)
I0311 13:27:21.224457 19870 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0311 13:27:21.576751 19870 solver.cpp:237] Iteration 7400, loss = 0.00626292
I0311 13:27:21.576786 19870 solver.cpp:253]     Train net output #0: loss = 0.00626306 (* 1 = 0.00626306 loss)
I0311 13:27:21.576795 19870 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0311 13:27:21.925236 19870 solver.cpp:341] Iteration 7500, Testing net (#0)
I0311 13:27:22.139755 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9911
I0311 13:27:22.139788 19870 solver.cpp:409]     Test net output #1: loss = 0.0295296 (* 1 = 0.0295296 loss)
I0311 13:27:22.141451 19870 solver.cpp:237] Iteration 7500, loss = 0.00272592
I0311 13:27:22.141474 19870 solver.cpp:253]     Train net output #0: loss = 0.00272606 (* 1 = 0.00272606 loss)
I0311 13:27:22.141486 19870 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0311 13:27:22.498298 19870 solver.cpp:237] Iteration 7600, loss = 0.0044142
I0311 13:27:22.498330 19870 solver.cpp:253]     Train net output #0: loss = 0.00441433 (* 1 = 0.00441433 loss)
I0311 13:27:22.498339 19870 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0311 13:27:22.856463 19870 solver.cpp:237] Iteration 7700, loss = 0.0233341
I0311 13:27:22.856498 19870 solver.cpp:253]     Train net output #0: loss = 0.0233342 (* 1 = 0.0233342 loss)
I0311 13:27:22.856508 19870 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0311 13:27:23.212484 19870 solver.cpp:237] Iteration 7800, loss = 0.00404889
I0311 13:27:23.212518 19870 solver.cpp:253]     Train net output #0: loss = 0.00404903 (* 1 = 0.00404903 loss)
I0311 13:27:23.212527 19870 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0311 13:27:23.573271 19870 solver.cpp:237] Iteration 7900, loss = 0.00533557
I0311 13:27:23.573304 19870 solver.cpp:253]     Train net output #0: loss = 0.00533572 (* 1 = 0.00533572 loss)
I0311 13:27:23.573313 19870 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0311 13:27:23.924000 19870 solver.cpp:341] Iteration 8000, Testing net (#0)
I0311 13:27:24.129437 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9906
I0311 13:27:24.129468 19870 solver.cpp:409]     Test net output #1: loss = 0.0285605 (* 1 = 0.0285605 loss)
I0311 13:27:24.131148 19870 solver.cpp:237] Iteration 8000, loss = 0.00662868
I0311 13:27:24.131167 19870 solver.cpp:253]     Train net output #0: loss = 0.00662882 (* 1 = 0.00662882 loss)
I0311 13:27:24.131178 19870 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0311 13:27:24.491435 19870 solver.cpp:237] Iteration 8100, loss = 0.0134388
I0311 13:27:24.491469 19870 solver.cpp:253]     Train net output #0: loss = 0.0134389 (* 1 = 0.0134389 loss)
I0311 13:27:24.491479 19870 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0311 13:27:24.849117 19870 solver.cpp:237] Iteration 8200, loss = 0.0100615
I0311 13:27:24.849148 19870 solver.cpp:253]     Train net output #0: loss = 0.0100617 (* 1 = 0.0100617 loss)
I0311 13:27:24.849159 19870 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0311 13:27:25.207057 19870 solver.cpp:237] Iteration 8300, loss = 0.0285426
I0311 13:27:25.207090 19870 solver.cpp:253]     Train net output #0: loss = 0.0285428 (* 1 = 0.0285428 loss)
I0311 13:27:25.207099 19870 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0311 13:27:25.563911 19870 solver.cpp:237] Iteration 8400, loss = 0.00804454
I0311 13:27:25.563944 19870 solver.cpp:253]     Train net output #0: loss = 0.00804469 (* 1 = 0.00804469 loss)
I0311 13:27:25.563954 19870 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0311 13:27:25.921614 19870 solver.cpp:341] Iteration 8500, Testing net (#0)
I0311 13:27:26.135705 19870 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0311 13:27:26.135740 19870 solver.cpp:409]     Test net output #1: loss = 0.0281398 (* 1 = 0.0281398 loss)
I0311 13:27:26.137311 19870 solver.cpp:237] Iteration 8500, loss = 0.0058928
I0311 13:27:26.137331 19870 solver.cpp:253]     Train net output #0: loss = 0.00589295 (* 1 = 0.00589295 loss)
I0311 13:27:26.137343 19870 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0311 13:27:26.490767 19870 solver.cpp:237] Iteration 8600, loss = 0.000745345
I0311 13:27:26.490799 19870 solver.cpp:253]     Train net output #0: loss = 0.000745493 (* 1 = 0.000745493 loss)
I0311 13:27:26.490809 19870 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0311 13:27:26.836401 19870 solver.cpp:237] Iteration 8700, loss = 0.0018181
I0311 13:27:26.836437 19870 solver.cpp:253]     Train net output #0: loss = 0.00181824 (* 1 = 0.00181824 loss)
I0311 13:27:26.836477 19870 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0311 13:27:27.205286 19870 solver.cpp:237] Iteration 8800, loss = 0.00180833
I0311 13:27:27.205319 19870 solver.cpp:253]     Train net output #0: loss = 0.00180847 (* 1 = 0.00180847 loss)
I0311 13:27:27.205329 19870 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0311 13:27:27.560829 19870 solver.cpp:237] Iteration 8900, loss = 0.000561546
I0311 13:27:27.560863 19870 solver.cpp:253]     Train net output #0: loss = 0.000561691 (* 1 = 0.000561691 loss)
I0311 13:27:27.560873 19870 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0311 13:27:27.910409 19870 solver.cpp:341] Iteration 9000, Testing net (#0)
I0311 13:27:28.120821 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9912
I0311 13:27:28.120853 19870 solver.cpp:409]     Test net output #1: loss = 0.0274797 (* 1 = 0.0274797 loss)
I0311 13:27:28.122476 19870 solver.cpp:237] Iteration 9000, loss = 0.00828649
I0311 13:27:28.122498 19870 solver.cpp:253]     Train net output #0: loss = 0.00828664 (* 1 = 0.00828664 loss)
I0311 13:27:28.122509 19870 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0311 13:27:28.469290 19870 solver.cpp:237] Iteration 9100, loss = 0.00958339
I0311 13:27:28.469326 19870 solver.cpp:253]     Train net output #0: loss = 0.00958354 (* 1 = 0.00958354 loss)
I0311 13:27:28.469336 19870 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0311 13:27:28.827173 19870 solver.cpp:237] Iteration 9200, loss = 0.00359035
I0311 13:27:28.827208 19870 solver.cpp:253]     Train net output #0: loss = 0.0035905 (* 1 = 0.0035905 loss)
I0311 13:27:28.827217 19870 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0311 13:27:29.168556 19870 solver.cpp:237] Iteration 9300, loss = 0.00747217
I0311 13:27:29.168589 19870 solver.cpp:253]     Train net output #0: loss = 0.00747232 (* 1 = 0.00747232 loss)
I0311 13:27:29.168599 19870 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0311 13:27:29.510921 19870 solver.cpp:237] Iteration 9400, loss = 0.0183612
I0311 13:27:29.510952 19870 solver.cpp:253]     Train net output #0: loss = 0.0183613 (* 1 = 0.0183613 loss)
I0311 13:27:29.510962 19870 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0311 13:27:29.852397 19870 solver.cpp:341] Iteration 9500, Testing net (#0)
I0311 13:27:30.075397 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9894
I0311 13:27:30.075428 19870 solver.cpp:409]     Test net output #1: loss = 0.0327614 (* 1 = 0.0327614 loss)
I0311 13:27:30.077440 19870 solver.cpp:237] Iteration 9500, loss = 0.00364445
I0311 13:27:30.077463 19870 solver.cpp:253]     Train net output #0: loss = 0.0036446 (* 1 = 0.0036446 loss)
I0311 13:27:30.077474 19870 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0311 13:27:30.437317 19870 solver.cpp:237] Iteration 9600, loss = 0.00157939
I0311 13:27:30.437350 19870 solver.cpp:253]     Train net output #0: loss = 0.00157954 (* 1 = 0.00157954 loss)
I0311 13:27:30.437360 19870 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0311 13:27:30.793498 19870 solver.cpp:237] Iteration 9700, loss = 0.00238314
I0311 13:27:30.793530 19870 solver.cpp:253]     Train net output #0: loss = 0.00238329 (* 1 = 0.00238329 loss)
I0311 13:27:30.793540 19870 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0311 13:27:31.150050 19870 solver.cpp:237] Iteration 9800, loss = 0.0138232
I0311 13:27:31.150084 19870 solver.cpp:253]     Train net output #0: loss = 0.0138233 (* 1 = 0.0138233 loss)
I0311 13:27:31.150094 19870 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0311 13:27:31.513195 19870 solver.cpp:237] Iteration 9900, loss = 0.00642262
I0311 13:27:31.513227 19870 solver.cpp:253]     Train net output #0: loss = 0.00642277 (* 1 = 0.00642277 loss)
I0311 13:27:31.513236 19870 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0311 13:27:31.868813 19870 solver.cpp:459] Snapshotting to binary proto file examples/mnist/lenet_basic_iter_10000.caffemodel
I0311 13:27:32.260921 19870 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/lenet_basic_iter_10000.solverstate
I0311 13:27:32.265168 19870 solver.cpp:321] Iteration 10000, loss = 0.0033853
I0311 13:27:32.265193 19870 solver.cpp:341] Iteration 10000, Testing net (#0)
I0311 13:27:32.482312 19870 solver.cpp:409]     Test net output #0: accuracy = 0.9918
I0311 13:27:32.482344 19870 solver.cpp:409]     Test net output #1: loss = 0.0273357 (* 1 = 0.0273357 loss)
I0311 13:27:32.482352 19870 solver.cpp:326] Optimization Done.
I0311 13:27:32.482357 19870 caffe.cpp:215] Optimization Done.
